

# Proyecto final

## Introducci√≥n
El presente proyecto consta de 4 algoritmos los cuales vamos a comparar para determinar cu√°l es el m√°s eficiente y conveniente de utilizar en diversas situaciones. 
Culminamos la materia de Datos masivos la cual consta de 4 unidades, las cuales fueron muy interesantes y nos dejaron mucho conocimiento respecto al tema del big data, se aprendi√≥ bastante y lo que m√°s destacamos, son los temas de machine learning, ya que como sabemos, ML es uno de los temas que m√°s suenan en nuestra sociedad, entonces es necesario, estar a la vanguardia para implementar dichas tecnolog√≠as y no quedarnos atr√°s tecnol√≥gicamente hablando, nosotros, como futuros cient√≠ficos de datos, debemos conocer mejor que nadie, este tipo de algoritmos, a continuaci√≥n, vamos a presentar dichos algoritmos, los definiremos, los mostraremos, los compararemos para determinar, cu√°l es el mejor, en t√©rminos de rapidez y eficiencia.

# Marco te√≥rico de los algoritmos.

## Support Vector Machine (SVM): 
Es un algoritmo de aprendizaje supervisado que se utiliza en muchos problemas de clasificaci√≥n y regresi√≥n, incluidas aplicaciones m√©dicas de procesamiento de se√±ales, procesamiento del lenguaje natural y reconocimiento de im√°genes y voz.

El objetivo del algoritmo SVM es encontrar un hiperplano que separe de la mejor forma posible dos clases diferentes de puntos de datos. ‚ÄúDe la mejor forma posible‚Äù implica el hiperplano con el margen m√°s amplio entre las dos clases, representado por los signos m√°s y menos en la siguiente figura. El margen se define como la anchura m√°xima de la regi√≥n paralela al hiperplano que no tiene puntos de datos interiores. El algoritmo solo puede encontrar este hiperplano en problemas que permiten separaci√≥n lineal; en la mayor√≠a de los problemas pr√°cticos, el algoritmo maximiza el margen flexible permitiendo un peque√±o n√∫mero de clasificaciones err√≥neas.


Referencia: 
- MATLAB. (2015, 2 marzo). Support Vector Machine (SVM). MATLAB & Simulink. Recuperado 5 de junio de 2022, de https://es.mathworks.com/discovery/support-vector-machine.html








## Decision Tree:
Los √°rboles de decisi√≥n son algoritmos estad√≠sticos o t√©cnicas de machine learning que nos permiten la construcci√≥n de modelos predictivos de anal√≠tica de datos para el Big Data basados en su clasificaci√≥n seg√∫n ciertas caracter√≠sticas o propiedades, o en la regresi√≥n mediante la relaci√≥n entre distintas variables para predecir el valor de otra.

En los modelos de clasificaci√≥n queremos predecir el valor de una variable mediante la clasificaci√≥n de la informaci√≥n en funci√≥n de otras variables (tipo, pertenencia a un grupo‚Ä¶). Por ejemplo, queremos pronosticar qu√© personas comprar√°n un determinado producto, clasificando entre clientes y no clientes, o qu√© marcas de port√°tiles comprar√° cada persona mediante la clasificaci√≥n entre las distintas marcas. Los valores a predecir son predefinidos, es decir, los resultados est√°n definidos en un conjunto de posibles valores.

En los modelos de regresi√≥n se intenta predecir el valor de una variable en funci√≥n de otras variables que son independientes entre s√≠. Por ejemplo, queremos predecir el precio de venta del terreno en funci√≥n de variables como su localizaci√≥n, superficie, distancia a la playa, etc. El posible resultado no forma parte de un conjunto predefinido, sino que puede tomar cualquier posible valor.

Referencia: 
- Unir, V. (2021, 19 octubre). √Årboles de decisi√≥n: en qu√© consisten y aplicaci√≥n en Big Data. UNIR. Recuperado 5 de junio de 2022, de https://www.unir.net/ingenieria/revista/arboles-de-decision/





## Logistic Regression: 
La Regresi√≥n Log√≠stica es un m√©todo estad√≠stico para predecir clases binarias. El resultado o variable objetivo es de naturaleza dicot√≥mica. Dicot√≥mica significa que solo hay dos clases posibles. Por ejemplo, se puede utilizar para problemas de detecci√≥n de c√°ncer o calcular la probabilidad de que ocurra un evento.

La Regresi√≥n Log√≠stica es uno de los algoritmos de Machine Learning m√°s simples y m√°s utilizados para la clasificaci√≥n de dos clases. Es f√°cil de implementar y se puede usar como l√≠nea de base para cualquier problema de clasificaci√≥n binaria. La Regresi√≥n Log√≠stica describe y estima la relaci√≥n entre una variable binaria dependiente y las variables independientes.

Referencia: 
- Gonzalez, L. (2020, 21 agosto). Regresi√≥n Log√≠stica - Teor√≠a. ü§ñ Aprende IA. Recuperado 5 de junio de 2022, de https://aprendeia.com/regresion-logistica-multiple-machine-learning-teoria/#:%7E:text=La%20Regresi%C3%B3n%20Log%C3%ADstica%20es%20uno,cualquier%20problema%20de%20clasificaci%C3%B3n%20binaria.

## Multilayer perceptron:
El perceptr√≥n multicapa (MLP) es un complemento de la red neuronal de avance. Consta de tres tipos de capas: la capa de entrada, la capa de salida y la capa oculta. La capa de entrada recibe la se√±al de entrada para ser procesada. La capa de salida realiza la tarea requerida, como la predicci√≥n y la clasificaci√≥n. Un n√∫mero arbitrario de capas ocultas que se colocan entre la capa de entrada y la de salida son el verdadero motor computacional del MLP. De manera similar a una red de avance en un MLP, los datos fluyen en la direcci√≥n de avance desde la capa de entrada a la de salida. Las neuronas en el MLP se entrenan con el algoritmo de aprendizaje de retropropagaci√≥n. Los MLP est√°n dise√±ados para aproximar cualquier funci√≥n continua y pueden resolver problemas que no son linealmente separables. Los principales casos de uso de MLP son la clasificaci√≥n, el reconocimiento, la predicci√≥n y la aproximaci√≥n de patrones.

Referencia: 
- Sciencedirect. (2014a, abril 1). Multilayer Perceptron. Recuperado 5 de junio de 2022, de https://www.sciencedirect.com/topics/computer-science/multilayer-perceptron


## Implementaci√≥n.
Para llevar a cabo la implementaci√≥n de los algoritmos anteriormente mencionados, hicimos uso del lenguaje de programaci√≥n spark/scala, ya que se trata de una herramienta muy poderosa para los t√≥picos de Big Data (Datos masivos) y adem√°s, es relativamente sencilla de utilizar, en realidad, la comparamos m√°s o menos con python, ya que no se trata de un lenguaje tan complejo en comparaci√≥n con otros. Las posibilidades que nos ofrece, son infinitas, siendo para nosotros, una de las herramientas top para trabajar, con datos masivos.

# Codigo
## SVM
~~~
//First we must tell spark to start counting the time since we run it, then we must import the libraries, start a simple session in spark
val start = System.currentTimeMillis
import org.apache.spark.ml.classification.LinearSVC
import org.apache.spark.ml.feature.{VectorAssembler, StringIndexer}
import org.apache.spark.ml.linalg.Vectors
import org.apache.spark.mllib.evaluation.MulticlassMetrics

import org.apache.log4j._
Logger.getLogger("org").setLevel(Level.ERROR)



val data = spark.read.option("header", "true").option("inferSchema","true").option("delimiter",";")csv("C:/Users/x/Documents/projet/bank-full.csv")

val lsvc = new LinearSVC().setMaxIter(10).setRegParam(0.1)

//Transform the categorical data to numeric
val labelIndexer = new StringIndexer().setInputCol("loan").setOutputCol("indexedLabel").fit(data)
val indexed = labelIndexer.transform(data).withColumnRenamed("indexedLabel", "label") 

//In order to avoid error we need to create 2 new columns label and features
//Here we create them using StringIndexer and VectorAssembler
val assembler = new VectorAssembler().setInputCols(Array("age", "balance", "day", "duration", "previous")).setOutputCol("features")
val features = assembler.transform(indexed)

val Array(training, test) = features.randomSplit(Array(0.7, 0.3), seed = 12345)

val lsvcModel = lsvc.fit(training)

val results = lsvcModel.transform(test)

val predictionAndLabels = results.select($"prediction",$"label").as[(Double, Double)].rdd
val metrics = new MulticlassMetrics(predictionAndLabels)

println("Confusion matrix:")
println(metrics.confusionMatrix)

metrics.accuracy

val error = 1 - metrics.accuracy

println(s"Coefficients: ${lsvcModel.coefficients} Intercept: ${lsvcModel.intercept}")

//Get the total time of the program execution
val totalTime = System.currentTimeMillis - start
println("Elapsed time: %1d ms".format(totalTime))

//Get the total of MB used 
val runtime = Runtime.getRuntime
val mb = 1024*1024
println("Used memory: " + (runtime.totalMemory - runtime.freeMemory) / mb + " MB")
~~~
## Desicion Tree
~~~
//First we must tell spark to start counting the time since we run it, then we must import the libraries, start a simple session in spark
val start = System.currentTimeMillis

import org.apache.spark.ml.Pipeline
import org.apache.spark.ml.classification.DecisionTreeClassificationModel
import org.apache.spark.ml.classification.DecisionTreeClassifier
import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator
import org.apache.spark.ml.feature.{VectorAssembler, IndexToString, StringIndexer, VectorIndexer}
import org.apache.spark.sql.SparkSession

import org.apache.log4j._
Logger.getLogger("org").setLevel(Level.ERROR)

val spark = SparkSession.builder().getOrCreate()

val data = spark.read.option("header", "true").option("inferSchema","true").option("delimiter",";")csv("C:/Users/x/Documents/projet/bank-full.csv")


//Transform the categorical data to numeric, merges the new data with the previous values
//this time with the numeric data and renames the loan column as label to use it in the execution
val labelIndexer = new StringIndexer().setInputCol("loan").setOutputCol("indexedLabel").fit(data)
val indexed = labelIndexer.transform(data).drop("loan").withColumnRenamed("indexedLabel", "label") 
val assembler = (new VectorAssembler().setInputCols(Array("age", "balance", "day", "duration", "previous")).setOutputCol("features"))
val features = assembler.transform(indexed)
val filter = features.withColumnRenamed("loan", "label")

val finalData = filter.select("label", "features")

// Index labels, adding metadata to the label column.
// Fit on whole dataset to include all labels into the index.
val labelIndexer = new StringIndexer().setInputCol("label").setOutputCol("indexedLabel").fit(finalData)
// Automatically identify categorical features and then index them.
val featureIndexer = new VectorIndexer().setInputCol("features").setOutputCol("indexedFeatures").setMaxCategories(4).fit(finalData)
// Split the data into training and test sets (30% held out for testing).
val Array(trainingData, testData) = finalData.randomSplit(Array(0.7, 0.3))

// Train a DecisionTree model.
val dt = new DecisionTreeClassifier().setLabelCol("indexedLabel").setFeaturesCol("indexedFeatures")

// Convert indexed labels back to original labels.
val labelConverter = new IndexToString().setInputCol("prediction").setOutputCol("predictedLabel").setLabels(labelIndexer.labels)

// Chain indexers and tree in a Pipeline.
val pipeline = new Pipeline().setStages(Array(labelIndexer, featureIndexer, dt, labelConverter))

// Train the model, this also runs the indexers.
val model = pipeline.fit(trainingData)

// Make the predictions.
val predictions = model.transform(testData)

// Select example rows to display. In this case there was only 5 rows to show.
predictions.select("predictedLabel", "label", "features").show(5)

// Select (prediction, true label)
val evaluator = new MulticlassClassificationEvaluator().setLabelCol("indexedLabel").setPredictionCol("prediction").setMetricName("accuracy")
// Compute the test error.
val accuracy = evaluator.evaluate(predictions)
println(s"Test Error = ${(1.0 - accuracy)}")

// Show by stages the classification of the tree model
val treeModel = model.stages(2).asInstanceOf[DecisionTreeClassificationModel]
println(s"Learned classification tree model:\n ${treeModel.toDebugString}")

//Get the total time of the program execution
val totalTime = System.currentTimeMillis - start
println("Elapsed time: %1d ms".format(totalTime))

//Get the total of MB used 
val runtime = Runtime.getRuntime
val mb = 1024*1024
println("Used memory: " + (runtime.totalMemory - runtime.freeMemory) / mb + " MB")
~~~
## Logistic Regression
~~~

~~~
 ## Multilayer perceptron.
 ~~~
 
 ~~~
 
 
# Conclusiones.

Podemos notar como cada algoritmo tiene distintas predicciones y cual es su margen de error, lo cual es interesante ya que se trabaj√≥ con el mismo archivo de datos (csv), es interesante el c√≥mo se puede manejar una gran cantidad de datos con, este tipo de algoritmos, nos llevamos un aprendizaje de c√≥mo usar estas herramientas y la gran cantidad de cosas que podemos realizar. En conclusi√≥n conforme efectividad el mejor de los algoritmos es el de SVM, ya que en los promedios muestra menor rango de error.

# Referencias.

- MATLAB. (2015, 2 marzo). Support Vector Machine (SVM). MATLAB & Simulink. Recuperado 5 de junio de 2022, de https://es.mathworks.com/discovery/support-vector-machine.html

- Unir, V. (2021, 19 octubre). √Årboles de decisi√≥n: en qu√© consisten y aplicaci√≥n en Big Data. UNIR. Recuperado 5 de junio de 2022, de https://www.unir.net/ingenieria/revista/arboles-de-decision/

- Gonzalez, L. (2020, 21 agosto). Regresi√≥n Log√≠stica - Teor√≠a. ü§ñ Aprende IA. Recuperado 5 de junio de 2022, de https://aprendeia.com/regresion-logistica-multiple-machine-learning-teoria/#:%7E:text=La%20Regresi%C3%B3n%20Log%C3%ADstica%20es%20uno,cualquier%20problema%20de%20clasificaci%C3%B3n%20binaria.

- Sciencedirect. (2014a, abril 1). Multilayer Perceptron. Recuperado 5 de junio de 2022, de https://www.sciencedirect.com/topics/computer-science/multilayer-perceptron






